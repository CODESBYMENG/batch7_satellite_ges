{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Stack Swift storage of the project\n",
    "\n",
    "### Recherche de points de mesure du satellite qui sont isolés, hors de la tendance de fond.\n",
    "Cette recherche correspond aux noise points clustering  Dbscan, c'est à dire les points qui n'appartiennent à aucun clusters, en effet :\n",
    "\n",
    "    - DBSCAN repose sur le concept de densité : \n",
    "    un cluster est une zone de l’espace où la densité d’observations est importante. En sortie, l’algorithme génère autant de clusters que de zones de l’espace de forte densité. Les points isolés sont considérés comme des outliers (valeurs aberrantes). Ce sont ces points qui nous intéressent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --user python-swiftclient python-keystoneclient --upgrade\n",
    "#!pip install nbdev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Datasets\n",
    "Using a config file for credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import swiftclient\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "#from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "class Datasets:\n",
    "    \"\"\"\n",
    "    Utility class to access the Open Stack Swift storage of the project.\n",
    "    \"\"\"\n",
    "    config = None # Dict configuration\n",
    "    conn = None # swiftclient.Connection object\n",
    "    container_name = 'oco2'\n",
    "    \n",
    "    def __init__(self, config_file):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        :param config_file: str, Path to config file\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # Load config\n",
    "        with open(config_file) as json_data_file:\n",
    "            self.config = json.load(json_data_file)\n",
    "        self.conn = self.swift_con()\n",
    "\n",
    "    def swift_con(self, config=None):\n",
    "        \"\"\"\n",
    "        Connect to Open Stack Swift\n",
    "        :param config: dict, Config dictionary.\n",
    "        :return: swiftclient.Connection\n",
    "        \"\"\"\n",
    "        if config is None:\n",
    "            config = self.config\n",
    "        user=config['swift_storage']['user']\n",
    "        key=config['swift_storage']['key']\n",
    "        auth_url=config['swift_storage']['auth_url']\n",
    "        tenant_name=config['swift_storage']['tenant_name']\n",
    "        auth_version=config['swift_storage']['auth_version']\n",
    "        options = config['swift_storage']['options']\n",
    "        self.conn = swiftclient.Connection(user=user,\n",
    "                                      key=key,\n",
    "                                      authurl=auth_url,\n",
    "                                      os_options=options,\n",
    "                                      tenant_name=tenant_name,\n",
    "                                      auth_version=auth_version)\n",
    "        return self.conn\n",
    "\n",
    "    def upload(self, mask='c:\\datasets\\*.csv', prefix=\"/Trash/\",content_type='text/csv', recursive=False):\n",
    "        \"\"\"\n",
    "        Upload files to Open Stack Swift\n",
    "        :param mask: str, Mask for seraching file to upload.\n",
    "        :param prefix: str, Prefix in destination. Useful to mimic folders.\n",
    "        :param content_type: str, Content type on the destination.\n",
    "        :param recursive: boolean, To allow search in sub-folder.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        for file in tqdm(glob.glob(mask, recursive=recursive)):\n",
    "            with open(file, 'rb') as one_file:\n",
    "                    upload_to = prefix+ os.path.basename(file)\n",
    "                    #print('Copy from',file,'to',upload_to)\n",
    "                    self.conn.put_object(self.container_name, upload_to,\n",
    "                                                    contents= one_file.read(),\n",
    "                                                    content_type=content_type) # 'text/csv'\n",
    "    def get_files_urls(self, pattern=\"\"):\n",
    "        result=[]\n",
    "        objects = self.conn.get_container(self.container_name)[1]\n",
    "        for data in objects:\n",
    "            if pattern in data['name']:\n",
    "                url = self.config['swift_storage']['base_url']+data['name']\n",
    "                result.append(url)\n",
    "        return result\n",
    "\n",
    "    def delete_files(self, pattern=\"/Trash/\", dry_run=True):\n",
    "        if dry_run:\n",
    "            print('Nothing will be deleted. Use dry_run=False to delete.')\n",
    "        for data in self.conn.get_container(self.container_name)[1]:\n",
    "            file = data['name']\n",
    "            if pattern in file:\n",
    "                print('deleting', file)\n",
    "                if not dry_run:\n",
    "                    self.conn.delete_object(self.container_name, file)\n",
    "                   \n",
    "\n",
    "    def get_containers(self):\n",
    "        return self.conn.get_account()[1]\n",
    "    def get_container(self, container_name='oco2'):\n",
    "        return self.conn.get_container(container_name)[1]\n",
    "\n",
    "    def get_url_from_sounding_id(self, sounding_id):\n",
    "        return config['swift_storage']['base_url']+'/datasets/oco-2/peaks-detected-details/peak_data-si_'+sounding_id+'.json'\n",
    "        \n",
    "    def get_dataframe(self, url):\n",
    "        \"\"\"\n",
    "        Read the url of a file and load it with Pandas\n",
    "        :param url: str, URL of the file to load.\n",
    "        :return: DataFrame\n",
    "        \"\"\"\n",
    "        # TODO : Switch to GeoPandas\n",
    "        df = None\n",
    "        extension = url.split('.')[-1].lower()\n",
    "        if extension == 'csv':\n",
    "            df = pd.read_csv(url)\n",
    "            df['sounding_id']= df['sounding_id'].astype(str)\n",
    "        elif extension == 'json':\n",
    "            df = pd.read_json(url)\n",
    "        return df\n",
    "    \n",
    "    def get_gaussian_param(self, sounding_id, df_all_peak):\n",
    "        df_param = df_all_peak.query(\"sounding_id==@sounding_id\")\n",
    "        if len(df_param)<1:\n",
    "            print('ERROR : sounding_id not found in dataframe !')\n",
    "            return {'slope' : 1,'intercept' : 1,'amplitude' : 1,'sigma': 1,'delta': 1,'R' : 1}\n",
    "        param_index = df_param.index[0]\n",
    "\n",
    "        gaussian_param = {\n",
    "            'slope' : df_param.loc[param_index, 'slope'],\n",
    "            'intercept' : df_param.loc[param_index, 'intercept'],\n",
    "            'amplitude' : df_param.loc[param_index, 'amplitude'],\n",
    "            'sigma': df_param.loc[param_index, 'sigma'],\n",
    "            'delta': df_param.loc[param_index, 'delta'],\n",
    "            'R' : df_param.loc[param_index, 'R'],\n",
    "        }\n",
    "        return gaussian_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = '../configs/config.json'\n",
    "datasets = Datasets(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get containers names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container name: oco2\n"
     ]
    }
   ],
   "source": [
    "for container in datasets.get_containers():\n",
    "    print('Container name:', container['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.get_files_urls('html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get files objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = datasets.get_container('oco2')\n",
    "for data in objects:\n",
    "    if 'oco2_1504' in data['name']:\n",
    "        print('{0}\\t{1}\\t{2}'.format(data['name'], data['bytes'], data['last_modified']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.76it/s]\n"
     ]
    }
   ],
   "source": [
    "datasets.upload(mask='../*.md', prefix=\"/Trash/\",content_type='text/text')\n",
    "# datasets.(\"/media/data-nvme/dev/datasets/OCO2/csv/*.csv\", \"/datasets/oco-2/peaks-detected/\", 'text/csv')\n",
    "# datasets.(\"/media/data-nvme/dev/datasets/OCO2/csv/*.json\", \"/datasets/oco-2/peaks-detected-details/\", 'application/json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://storage.gra.cloud.ovh.net/v1/AUTH_2...d/oco2//Trash/CONTRIBUTING.md',\n",
       " 'https://storage.gra.cloud.ovh.net/v1/AUTH_2...d/oco2//Trash/README.md']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.get_files_urls('/Trash/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload HTML\n",
    "Setting content type to 'text/html' allow the file to be display by browsers, without downloading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets.upload(\"chemin/peaks_and_sources.html\", \"/Trash/\", 'text/html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting /Trash/CONTRIBUTING.md\n",
      "deleting /Trash/README.md\n"
     ]
    }
   ],
   "source": [
    "datasets.delete_files(\"/Trash/\", dry_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orbit</th>\n",
       "      <th>sounding_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>xco2</th>\n",
       "      <th>xco2_uncert</th>\n",
       "      <th>windspeed_u</th>\n",
       "      <th>windspeed_v</th>\n",
       "      <th>surface_pressure_apriori</th>\n",
       "      <th>surface_pressure</th>\n",
       "      <th>altitude</th>\n",
       "      <th>land_water_indicator</th>\n",
       "      <th>land_fraction</th>\n",
       "      <th>latitude_orig</th>\n",
       "      <th>longitude_orig</th>\n",
       "      <th>distance</th>\n",
       "      <th>xco2_enhancement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22061</td>\n",
       "      <td>2018082505140535</td>\n",
       "      <td>35.290813</td>\n",
       "      <td>117.642830</td>\n",
       "      <td>400.878540</td>\n",
       "      <td>0.559905</td>\n",
       "      <td>-2.961818</td>\n",
       "      <td>-0.434006</td>\n",
       "      <td>983.626465</td>\n",
       "      <td>981.835144</td>\n",
       "      <td>218.204407</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>-43.749119</td>\n",
       "      <td>135.989822</td>\n",
       "      <td>-99.458018</td>\n",
       "      <td>-0.413101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22061</td>\n",
       "      <td>2018082505140503</td>\n",
       "      <td>35.292336</td>\n",
       "      <td>117.637512</td>\n",
       "      <td>400.439972</td>\n",
       "      <td>0.567133</td>\n",
       "      <td>-2.958889</td>\n",
       "      <td>-0.431859</td>\n",
       "      <td>981.793701</td>\n",
       "      <td>984.246216</td>\n",
       "      <td>234.751266</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>-43.749119</td>\n",
       "      <td>135.989822</td>\n",
       "      <td>-99.182306</td>\n",
       "      <td>-0.851669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22061</td>\n",
       "      <td>2018082505140608</td>\n",
       "      <td>35.297531</td>\n",
       "      <td>117.647171</td>\n",
       "      <td>400.820587</td>\n",
       "      <td>0.667865</td>\n",
       "      <td>-2.963000</td>\n",
       "      <td>-0.423906</td>\n",
       "      <td>984.632263</td>\n",
       "      <td>984.782532</td>\n",
       "      <td>209.161057</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>-43.749119</td>\n",
       "      <td>135.989822</td>\n",
       "      <td>-98.822275</td>\n",
       "      <td>-0.471054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   orbit       sounding_id   latitude   longitude        xco2  xco2_uncert  \\\n",
       "0  22061  2018082505140535  35.290813  117.642830  400.878540     0.559905   \n",
       "1  22061  2018082505140503  35.292336  117.637512  400.439972     0.567133   \n",
       "2  22061  2018082505140608  35.297531  117.647171  400.820587     0.667865   \n",
       "\n",
       "   windspeed_u  windspeed_v  surface_pressure_apriori  surface_pressure  \\\n",
       "0    -2.961818    -0.434006                983.626465        981.835144   \n",
       "1    -2.958889    -0.431859                981.793701        984.246216   \n",
       "2    -2.963000    -0.423906                984.632263        984.782532   \n",
       "\n",
       "     altitude  land_water_indicator  land_fraction  latitude_orig  \\\n",
       "0  218.204407                     0            100     -43.749119   \n",
       "1  234.751266                     0            100     -43.749119   \n",
       "2  209.161057                     0            100     -43.749119   \n",
       "\n",
       "   longitude_orig   distance  xco2_enhancement  \n",
       "0      135.989822 -99.458018         -0.413101  \n",
       "1      135.989822 -99.182306         -0.851669  \n",
       "2      135.989822 -98.822275         -0.471054  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=datasets.get_dataframe('https://storage.gra.cloud.ovh.net/v1/AUTH_2aaacef8e88a4ca897bb93b984bd04dd/oco2//datasets/oco-2/peaks-detected-details/peak_data-si_2018082505142073.json')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul de toutes les distances entre les lignes\n",
    "1) ne conserve que les variables concernées par le calcul de distance\n",
    "2) standardisation des data\n",
    "3) calculer les distances\n",
    "4) après nous sommes dans une problématique de clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['orbit', 'sounding_id', 'latitude', 'longitude', 'xco2', 'xco2_uncert', 'windspeed_u', 'windspeed_v', 'surface_pressure_apriori', 'surface_pressure', 'altitude', 'land_water_indicator', 'land_fraction', 'latitude_orig', 'longitude_orig', 'distance', 'xco2_enhancement']\n"
     ]
    }
   ],
   "source": [
    "lst = list(df.columns)\n",
    "print(lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in ['orbit', 'sounding_id', 'latitude', 'longitude']:\n",
    "    lst.remove(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Les variables entrantes dans le calcul de la densité des point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xco2',\n",
       " 'xco2_uncert',\n",
       " 'windspeed_u',\n",
       " 'windspeed_v',\n",
       " 'surface_pressure_apriori',\n",
       " 'surface_pressure',\n",
       " 'altitude',\n",
       " 'land_water_indicator',\n",
       " 'land_fraction',\n",
       " 'latitude_orig',\n",
       " 'longitude_orig',\n",
       " 'distance',\n",
       " 'xco2_enhancement']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst\n",
    "data = df[lst]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaled data has zero mean and unit variance:\n",
    "- standardisation du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- scaled\n",
      "[[-0.48320878 -1.00370044 -1.11069355 ...  0.         -1.95489176\n",
      "  -0.48320878]\n",
      " [-0.77402376 -0.92000131 -1.07759097 ...  0.         -1.94980217\n",
      "  -0.77402376]\n",
      " [-0.52163739  0.24649317 -1.12404289 ...  0.         -1.94315609\n",
      "  -0.52163739]\n",
      " ...\n",
      " [-0.57384689  2.01126288  3.18149104 ...  0.          1.71373452\n",
      "  -0.57384689]\n",
      " [-0.31051272  0.24957435  3.22139626 ...  0.          1.71479238\n",
      "  -0.31051272]\n",
      " [-0.94544493  2.04753506  3.31048253 ...  0.          1.72562806\n",
      "  -0.94544493]]\n",
      "- std 0.9576845844606717\n",
      "means -0.07692307692307639\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "scaler = preprocessing.StandardScaler().fit(data)\n",
    "\n",
    "z = scaler.transform(data)\n",
    "print('- scaled')\n",
    "print(z)\n",
    "\n",
    "print('- std', np.std(z))\n",
    "print('means', np.mean(z))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recherche des points isolés\n",
    "1) recherche des hyperparamètres optimaux   \n",
    "2) clustering et extraction des points isolés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recherche d'un parametre eps optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_dbcluster(z, eps=0.9, min_samples=10):\n",
    "    ''' Dbscan clustering '''\n",
    "    '''\n",
    "    input:\n",
    "    z : standardized data\n",
    "    eps : Epsilon, mesure du voisinage \n",
    "    (deux points sont voisins quand ils sont à une distance plus petite que epsilon l un de l autre\n",
    "    min_samples : nombre de points minimal pour créer un cluster\n",
    "    \n",
    "    par défault < 10 pts sont des points isolés \n",
    "    \n",
    "    output:\n",
    "    db : model dbscan\n",
    "    class_member_mask : mask des points isoles\n",
    "    '''\n",
    "    \n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples).fit(z)\n",
    "    core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "    core_samples_mask[db.core_sample_indices_] = True\n",
    "    labels = db.labels_\n",
    "    \n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise_ = list(labels).count(-1)\n",
    "    print('Estimated number of clusters: %d' % n_clusters_, ', eps:', eps)\n",
    "    print('Estimated number of noise points: %d' % n_noise_, ', eps:', eps)\n",
    "    print(\"Silhouette Coefficient: %0.3f\" % metrics.silhouette_score(z, labels))\n",
    "\n",
    "    core_samples_mask[db.core_sample_indices_] = True\n",
    "    k = -1 \n",
    "    class_member_mask = (labels == k)\n",
    "\n",
    "    return db, class_member_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps 0.5\n",
      "Estimated number of clusters: 14 , eps: 0.5\n",
      "Estimated number of noise points: 346 , eps: 0.5\n",
      "Silhouette Coefficient: -0.271\n",
      "eps 0.6\n",
      "Estimated number of clusters: 15 , eps: 0.6\n",
      "Estimated number of noise points: 223 , eps: 0.6\n",
      "Silhouette Coefficient: -0.077\n",
      "eps 0.7\n",
      "Estimated number of clusters: 8 , eps: 0.7\n",
      "Estimated number of noise points: 149 , eps: 0.7\n",
      "Silhouette Coefficient: -0.000\n",
      "eps 0.75\n",
      "Estimated number of clusters: 7 , eps: 0.75\n",
      "Estimated number of noise points: 107 , eps: 0.75\n",
      "Silhouette Coefficient: 0.166\n",
      "eps 0.8\n",
      "Estimated number of clusters: 4 , eps: 0.8\n",
      "Estimated number of noise points: 89 , eps: 0.8\n",
      "Silhouette Coefficient: 0.221\n",
      "eps 0.85\n",
      "Estimated number of clusters: 4 , eps: 0.85\n",
      "Estimated number of noise points: 77 , eps: 0.85\n",
      "Silhouette Coefficient: 0.228\n",
      "eps 0.9\n",
      "Estimated number of clusters: 3 , eps: 0.9\n",
      "Estimated number of noise points: 67 , eps: 0.9\n",
      "Silhouette Coefficient: 0.301\n"
     ]
    }
   ],
   "source": [
    "# Compute DBSCAN\n",
    "tab_eps = [0.5, 0.6, 0.7, 0.75, 0.8, 0.85, 0.9]\n",
    "min_samples = 5\n",
    "for eps in tab_eps:\n",
    "    print('eps', eps)\n",
    "    _, _ = do_dbcluster(z, eps, min_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choix stratégique, \n",
    "- les plus simple consiste a afficher les points isoles et les autres sur un graphique en deux couleurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 4 , eps: 0.85\n",
      "Estimated number of noise points: 77 , eps: 0.85\n",
      "Silhouette Coefficient: 0.228\n"
     ]
    }
   ],
   "source": [
    "#### Les points isolés pour un eps de ..\n",
    "#### a verifier sur un graphique\n",
    "if True:\n",
    "    eps = 0.85\n",
    "    min_samples = 5\n",
    "    db, class_member_mask = do_dbcluster(z, eps, min_samples)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "les points dans les clusters (475, 17)\n",
      "les points isoles (77, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>altitude</th>\n",
       "      <th>distance</th>\n",
       "      <th>land_fraction</th>\n",
       "      <th>land_water_indicator</th>\n",
       "      <th>latitude</th>\n",
       "      <th>latitude_orig</th>\n",
       "      <th>longitude</th>\n",
       "      <th>longitude_orig</th>\n",
       "      <th>orbit</th>\n",
       "      <th>sounding_id</th>\n",
       "      <th>surface_pressure</th>\n",
       "      <th>surface_pressure_apriori</th>\n",
       "      <th>windspeed_u</th>\n",
       "      <th>windspeed_v</th>\n",
       "      <th>xco2</th>\n",
       "      <th>xco2_enhancement</th>\n",
       "      <th>xco2_uncert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>207.826263</td>\n",
       "      <td>-95.514451</td>\n",
       "      <td>91.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.325920</td>\n",
       "      <td>-43.749119</td>\n",
       "      <td>117.635780</td>\n",
       "      <td>135.989822</td>\n",
       "      <td>22061.0</td>\n",
       "      <td>2.018083e+15</td>\n",
       "      <td>980.419373</td>\n",
       "      <td>984.789673</td>\n",
       "      <td>-2.952792</td>\n",
       "      <td>-0.382215</td>\n",
       "      <td>402.204193</td>\n",
       "      <td>0.912552</td>\n",
       "      <td>0.560314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>305.329376</td>\n",
       "      <td>-94.031567</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.337620</td>\n",
       "      <td>-43.749119</td>\n",
       "      <td>117.625359</td>\n",
       "      <td>135.989822</td>\n",
       "      <td>22061.0</td>\n",
       "      <td>2.018083e+15</td>\n",
       "      <td>976.453674</td>\n",
       "      <td>974.018433</td>\n",
       "      <td>-2.945526</td>\n",
       "      <td>-0.365604</td>\n",
       "      <td>403.342834</td>\n",
       "      <td>2.051193</td>\n",
       "      <td>0.651326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>349.941772</td>\n",
       "      <td>-92.452384</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.353027</td>\n",
       "      <td>-43.749119</td>\n",
       "      <td>117.629517</td>\n",
       "      <td>135.989822</td>\n",
       "      <td>22061.0</td>\n",
       "      <td>2.018083e+15</td>\n",
       "      <td>973.209717</td>\n",
       "      <td>969.121826</td>\n",
       "      <td>-2.945274</td>\n",
       "      <td>-0.342623</td>\n",
       "      <td>401.489441</td>\n",
       "      <td>0.197800</td>\n",
       "      <td>0.712861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>299.793091</td>\n",
       "      <td>-90.472100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.367142</td>\n",
       "      <td>-43.749119</td>\n",
       "      <td>117.607788</td>\n",
       "      <td>135.989822</td>\n",
       "      <td>22061.0</td>\n",
       "      <td>2.018083e+15</td>\n",
       "      <td>975.678406</td>\n",
       "      <td>974.635864</td>\n",
       "      <td>-2.931464</td>\n",
       "      <td>-0.323926</td>\n",
       "      <td>403.928772</td>\n",
       "      <td>2.637131</td>\n",
       "      <td>0.745471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>223.182571</td>\n",
       "      <td>-87.075481</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.399319</td>\n",
       "      <td>-43.749119</td>\n",
       "      <td>117.611740</td>\n",
       "      <td>135.989822</td>\n",
       "      <td>22061.0</td>\n",
       "      <td>2.018083e+15</td>\n",
       "      <td>985.541565</td>\n",
       "      <td>983.111206</td>\n",
       "      <td>-2.928306</td>\n",
       "      <td>-0.276691</td>\n",
       "      <td>401.913239</td>\n",
       "      <td>0.621597</td>\n",
       "      <td>0.710786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     altitude   distance  land_fraction  land_water_indicator   latitude  \\\n",
       "0  207.826263 -95.514451           91.0                   3.0  35.325920   \n",
       "1  305.329376 -94.031567          100.0                   0.0  35.337620   \n",
       "2  349.941772 -92.452384          100.0                   0.0  35.353027   \n",
       "3  299.793091 -90.472100          100.0                   0.0  35.367142   \n",
       "4  223.182571 -87.075481          100.0                   0.0  35.399319   \n",
       "\n",
       "   latitude_orig   longitude  longitude_orig    orbit   sounding_id  \\\n",
       "0     -43.749119  117.635780      135.989822  22061.0  2.018083e+15   \n",
       "1     -43.749119  117.625359      135.989822  22061.0  2.018083e+15   \n",
       "2     -43.749119  117.629517      135.989822  22061.0  2.018083e+15   \n",
       "3     -43.749119  117.607788      135.989822  22061.0  2.018083e+15   \n",
       "4     -43.749119  117.611740      135.989822  22061.0  2.018083e+15   \n",
       "\n",
       "   surface_pressure  surface_pressure_apriori  windspeed_u  windspeed_v  \\\n",
       "0        980.419373                984.789673    -2.952792    -0.382215   \n",
       "1        976.453674                974.018433    -2.945526    -0.365604   \n",
       "2        973.209717                969.121826    -2.945274    -0.342623   \n",
       "3        975.678406                974.635864    -2.931464    -0.323926   \n",
       "4        985.541565                983.111206    -2.928306    -0.276691   \n",
       "\n",
       "         xco2  xco2_enhancement  xco2_uncert  \n",
       "0  402.204193          0.912552     0.560314  \n",
       "1  403.342834          2.051193     0.651326  \n",
       "2  401.489441          0.197800     0.712861  \n",
       "3  403.928772          2.637131     0.745471  \n",
       "4  401.913239          0.621597     0.710786  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if True:\n",
    "    df_isole = pd.DataFrame()\n",
    "    df_incluster = pd.DataFrame()\n",
    "\n",
    "    for index, r in df.iterrows():\n",
    "        if class_member_mask[index]:\n",
    "            df_isole = df_isole.append(r, ignore_index=True)\n",
    "        else:\n",
    "            df_incluster = df_incluster.append(r, ignore_index=True)\n",
    "    print('les points dans les clusters', df_incluster.shape)        \n",
    "    print('les points isoles', df_isole.shape)        \n",
    "    display(df_isole.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Affichage des points isole, et les autres sur un graphique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted datasets.ipynb.\n",
      "Converted find_peak.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted map.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
