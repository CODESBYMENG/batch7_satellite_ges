{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Find Peaks with LSTM-autoencoders.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dataforgoodfr/batch7_satellite_ges/blob/master/Find_Peaks_with_LSTM_autoencoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRjVjoFK0X-I",
        "colab_type": "text"
      },
      "source": [
        "# Importing Libraries and Loading Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-gtPtL90faW",
        "colab_type": "code",
        "outputId": "ce4f5c13-3c9b-49ec-9dd7-159b95dba3c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "import pandas as pd \n",
        "%matplotlib inline \n",
        "import os \n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#data_1610 = pd.read_csv(\"http://courty.fr/OCO2/oco2_1610.csv\", sep=\";\")\n",
        "#data_1705 = pd.read_csv(\"http://courty.fr/OCO2/oco2_1705.csv\", sep=\";\")\n",
        "#data_1803 = pd.read_csv(\"http://courty.fr/OCO2/oco2_1803.csv\", sep=\";\")\n",
        "#data_1805 = pd.read_csv(\"http://courty.fr/OCO2/oco2_1805.csv\", sep=\";\")\n",
        "data_1808 = pd.read_csv(\"/content/oco2_1808_light.csv\", sep=\";\")\n",
        "#data_1809 = pd.read_csv(\"http://courty.fr/OCO2/oco2_1809.csv\", sep=\";\")\n",
        "\n",
        "data_1808.head()\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sounding_id</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>xco2</th>\n",
              "      <th>xco2_uncert</th>\n",
              "      <th>orbit</th>\n",
              "      <th>windspeed_u</th>\n",
              "      <th>windspeed_v</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018080100462105</td>\n",
              "      <td>-33.015541</td>\n",
              "      <td>-164.508881</td>\n",
              "      <td>405.143188</td>\n",
              "      <td>0.491368</td>\n",
              "      <td>21709</td>\n",
              "      <td>3.749916</td>\n",
              "      <td>9.128431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018080100462137</td>\n",
              "      <td>-32.988529</td>\n",
              "      <td>-164.553787</td>\n",
              "      <td>404.893677</td>\n",
              "      <td>0.497189</td>\n",
              "      <td>21709</td>\n",
              "      <td>3.720200</td>\n",
              "      <td>9.087859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018080100462171</td>\n",
              "      <td>-32.996235</td>\n",
              "      <td>-164.435699</td>\n",
              "      <td>404.729431</td>\n",
              "      <td>0.537358</td>\n",
              "      <td>21709</td>\n",
              "      <td>3.815527</td>\n",
              "      <td>9.151507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018080100462172</td>\n",
              "      <td>-32.992409</td>\n",
              "      <td>-164.455872</td>\n",
              "      <td>404.819550</td>\n",
              "      <td>0.498803</td>\n",
              "      <td>21709</td>\n",
              "      <td>3.799832</td>\n",
              "      <td>9.138914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018080100462173</td>\n",
              "      <td>-32.988403</td>\n",
              "      <td>-164.476196</td>\n",
              "      <td>404.706451</td>\n",
              "      <td>0.496855</td>\n",
              "      <td>21709</td>\n",
              "      <td>3.783962</td>\n",
              "      <td>9.126184</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        sounding_id   latitude   longitude  ...  orbit  windspeed_u  windspeed_v\n",
              "0  2018080100462105 -33.015541 -164.508881  ...  21709     3.749916     9.128431\n",
              "1  2018080100462137 -32.988529 -164.553787  ...  21709     3.720200     9.087859\n",
              "2  2018080100462171 -32.996235 -164.435699  ...  21709     3.815527     9.151507\n",
              "3  2018080100462172 -32.992409 -164.455872  ...  21709     3.799832     9.138914\n",
              "4  2018080100462173 -32.988403 -164.476196  ...  21709     3.783962     9.126184\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNhDWuWx0hkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = data_1808[0:10000]\n",
        "test = data_1808[10000:11000]\n",
        "TIME_STEPS = 30\n",
        "\n",
        "# reshape to [samples, time_steps, n_features]\n",
        "\n",
        "def createDataset(df,timeStep=30):\n",
        "  Xs, ys = [], []\n",
        "\n",
        "  for i in range(len(train) - TIME_STEPS):\n",
        "      v = train[['xco2']].iloc[i:(i + TIME_STEPS)].values\n",
        "      #y = train.iloc[i+TIME_STEPS, train.columns.get_loc('xco2')]\n",
        "      v = torch.tensor(v).float() \n",
        "      \n",
        "      Xs.append(v)\n",
        "  \n",
        "  return torch.stack(Xs)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s0bjYH81iR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = createDataset(train)\n",
        "X_test = createDataset(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Sl8rj0z2onQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "  def __init__(self, seq_len, n_features, embedding_dim=64):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.seq_len, self.n_features = seq_len, n_features\n",
        "    self.embedding_dim, self.hidden_dim = embedding_dim, 2 * embedding_dim\n",
        "\n",
        "    self.rnn1 = nn.LSTM(\n",
        "      input_size=n_features,\n",
        "      hidden_size=self.hidden_dim,\n",
        "      num_layers=1,\n",
        "      batch_first=True\n",
        "    )\n",
        "\n",
        "    self.rnn2 = nn.LSTM(\n",
        "      input_size=self.hidden_dim,\n",
        "      hidden_size=embedding_dim,\n",
        "      num_layers=1,\n",
        "      batch_first=True\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.reshape((1, self.seq_len, self.n_features))\n",
        "    \n",
        "    x, (_, _) = self.rnn1(x)\n",
        "    x, (hidden_n, _) = self.rnn2(x)\n",
        "\n",
        "\n",
        "    return hidden_n.reshape((self.n_features, self.embedding_dim))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hvx7uy1H2mtI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "\n",
        "  def __init__(self, seq_len, input_dim=64, n_features=1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.seq_len, self.input_dim = seq_len, input_dim\n",
        "    self.hidden_dim, self.n_features = 2 * input_dim, n_features\n",
        "\n",
        "    self.rnn1 = nn.LSTM(\n",
        "      input_size=input_dim,\n",
        "      hidden_size=input_dim,\n",
        "      num_layers=1,\n",
        "      batch_first=True\n",
        "    )\n",
        "\n",
        "    self.rnn2 = nn.LSTM(\n",
        "      input_size=input_dim,\n",
        "      hidden_size=self.hidden_dim,\n",
        "      num_layers=1,\n",
        "      batch_first=True\n",
        "    )\n",
        "\n",
        "    self.output_layer = nn.Linear(self.hidden_dim, n_features)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.repeat(self.seq_len, self.n_features)\n",
        "    x = x.reshape((self.n_features, self.seq_len, self.input_dim))\n",
        "\n",
        "    x, (hidden_n, cell_n) = self.rnn1(x)\n",
        "    x, (hidden_n, cell_n) = self.rnn2(x)\n",
        "    x = x.reshape((self.seq_len, self.hidden_dim))\n",
        "\n",
        "    return self.output_layer(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJxOIvQK2Vpn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RecurrentAutoencoder(nn.Module):\n",
        "\n",
        "  def __init__(self, seq_len, n_features, embedding_dim=64):\n",
        "    super(RecurrentAutoencoder, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(seq_len, n_features, embedding_dim).to(device)\n",
        "    self.decoder = Decoder(seq_len, embedding_dim, n_features).to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.encoder(x)\n",
        "    x = self.decoder(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZcXh3kZ2ulp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, train_dataset, val_dataset, optimizer, start_epoch, n_epochs):\n",
        "  criterion = nn.MSELoss()\n",
        "  history = dict(train=[], val=[])\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  best_loss = 10000.0\n",
        "\n",
        "  for epoch in tqdm(range(start_epoch, n_epochs + 1)):\n",
        "    \n",
        "    model = model.train()\n",
        "\n",
        "    train_losses = []\n",
        "    for seq_true in train_dataset:\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      seq_true = seq_true.to(device)\n",
        "      seq_pred = model(seq_true)\n",
        "\n",
        "      loss = criterion(seq_pred, seq_true)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      train_losses.append(loss.item())\n",
        "\n",
        "    val_losses = []\n",
        "    model = model.eval()\n",
        "    with torch.no_grad():\n",
        "      for seq_true in val_dataset:\n",
        "\n",
        "        seq_true = seq_true.to(device)\n",
        "        seq_pred = model(seq_true)\n",
        "\n",
        "        loss = criterion(seq_pred, seq_true)\n",
        "        val_losses.append(loss.item())\n",
        "\n",
        "    train_loss = np.mean(train_losses)\n",
        "    val_loss = np.mean(val_losses)\n",
        "\n",
        "    history['train'].append(train_loss)\n",
        "    history['val'].append(val_loss)\n",
        "\n",
        "    #if val_loss < best_loss:\n",
        "     # best_loss = val_loss\n",
        "     # best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    savePath = \"/content/drive/My Drive/classifier.pt\" \n",
        "\n",
        "    checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "        }\n",
        "        \n",
        "    torch.save(checkpoint, savePath)\n",
        "    \n",
        "    print('Epoch {0}: train loss {1} val loss {2}'.format(epoch, train_loss,val_loss))\n",
        "\n",
        "\n",
        "\n",
        "  model.load_state_dict(best_model_wts)\n",
        "  return model.eval(), history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlAKr6Qa_EIm",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLddj7qc278k",
        "colab_type": "code",
        "outputId": "4b5d5e6b-8a68-4595-aaf2-9b81f89c92ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "savePath = \"/content/drive/My Drive/classifier.pt\" \n",
        "\n",
        "model = RecurrentAutoencoder(30, 1, 128)\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "checkpoint = torch.load(savePath)\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "\n",
        "model, history = train_model(\n",
        "  model,\n",
        "  X_train,\n",
        "  X_test,\n",
        "  optimizer,\n",
        "  checkpoint['epoch'],\n",
        "  n_epochs=1000\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/997 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  0%|          | 1/997 [01:51<30:50:59, 111.51s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4: train loss 272.9881053193761 val loss 267.107117048166\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  0%|          | 2/997 [03:45<30:59:44, 112.14s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 258.96917015083335 val loss 253.2745945768825\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  0%|          | 3/997 [05:38<31:05:06, 112.58s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6: train loss 245.32367397296872 val loss 239.8156703631402\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  0%|          | 4/997 [07:32<31:07:52, 112.86s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7: train loss 232.0514319524124 val loss 226.7300840341459\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 5/997 [09:24<31:04:13, 112.76s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8: train loss 219.1523270296118 val loss 214.01765236046273\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 6/997 [11:16<30:58:42, 112.54s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9: train loss 206.62631548362128 val loss 201.6782862564745\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 7/997 [13:08<30:51:03, 112.19s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10: train loss 194.47350493864406 val loss 189.71211965210819\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 8/997 [14:58<30:40:58, 111.69s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11: train loss 182.69369399703015 val loss 178.11878611756902\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 9/997 [16:49<30:36:17, 111.52s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12: train loss 171.2869758996227 val loss 166.89852856298387\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 10/997 [18:39<30:23:39, 110.86s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13: train loss 160.25346397774868 val loss 156.0515534518595\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 11/997 [20:28<30:12:51, 110.32s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14: train loss 149.59260222225515 val loss 145.57703304539473\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 12/997 [22:17<30:06:58, 110.07s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15: train loss 139.3054179261417 val loss 135.4767379538824\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|▏         | 13/997 [24:06<29:59:53, 109.75s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16: train loss 129.39159712490132 val loss 125.74949973822835\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|▏         | 14/997 [25:54<29:50:35, 109.29s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17: train loss 119.85021095161093 val loss 116.39406912219202\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  2%|▏         | 15/997 [27:42<29:40:23, 108.78s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18: train loss 110.68092518063223 val loss 107.41094757814705\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  2%|▏         | 16/997 [29:30<29:32:34, 108.41s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19: train loss 101.88406189867821 val loss 98.80047551559709\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  2%|▏         | 17/997 [31:17<29:25:09, 108.07s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20: train loss 93.45968186006384 val loss 90.56186467957951\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  2%|▏         | 18/997 [33:04<29:21:26, 107.95s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 21: train loss 85.40756280223728 val loss 82.69594926288876\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  2%|▏         | 19/997 [34:52<29:16:39, 107.77s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 22: train loss 77.72780175778189 val loss 75.20210654508386\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  2%|▏         | 20/997 [36:40<29:14:23, 107.74s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 23: train loss 70.42019310265391 val loss 68.08039228502463\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  2%|▏         | 21/997 [38:28<29:15:46, 107.94s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 24: train loss 63.484243244106096 val loss 61.330292739026405\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  2%|▏         | 22/997 [40:16<29:12:29, 107.85s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 25: train loss 56.92043141256962 val loss 54.9526181158833\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  2%|▏         | 23/997 [42:03<29:10:53, 107.86s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 26: train loss 50.72877567256824 val loss 48.94691856636805\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  2%|▏         | 24/997 [43:51<29:07:09, 107.74s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 27: train loss 44.90865908616046 val loss 43.311993650017435\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  3%|▎         | 25/997 [45:38<29:01:49, 107.52s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 28: train loss 39.45973598438137 val loss 38.04910105032811\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  3%|▎         | 26/997 [47:25<28:58:19, 107.41s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 29: train loss 34.38214179300138 val loss 33.15630118811023\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  3%|▎         | 27/997 [49:12<28:55:32, 107.35s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 30: train loss 29.67402923511287 val loss 28.632525552120228\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  3%|▎         | 28/997 [51:00<28:55:42, 107.47s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 31: train loss 25.335150666461665 val loss 24.477902302411998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  3%|▎         | 29/997 [52:47<28:53:48, 107.47s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 32: train loss 21.365569118511235 val loss 20.693090500635513\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  3%|▎         | 30/997 [54:35<28:53:21, 107.55s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 33: train loss 17.764615890039963 val loss 17.275293315114563\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  3%|▎         | 31/997 [56:23<28:51:29, 107.55s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 34: train loss 14.52999540011407 val loss 14.223251417001247\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  3%|▎         | 32/997 [58:11<28:50:49, 107.62s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 35: train loss 11.659833862119118 val loss 11.534249849089887\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  3%|▎         | 33/997 [59:59<28:53:05, 107.87s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 36: train loss 9.151617958122413 val loss 9.204955803307751\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  3%|▎         | 34/997 [1:01:47<28:51:15, 107.87s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 37: train loss 6.999915254319324 val loss 7.229641791977878\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmyb4mpxdPbG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "c491d414-1ed4-4c6a-da52-5216e3d549b7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "model(X_train[1].to(device))\n",
        "plt.plot(model(X_train[1].to(device)).cpu().detach().numpy())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7feab851bf60>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db0zuy0oI8vV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, dataset):\n",
        "  predictions, losses = [], []\n",
        "  criterion = nn.MSELoss().to(device)\n",
        "  with torch.no_grad():\n",
        "    model = model.eval()\n",
        "    for seq_true in dataset:\n",
        "      seq_true = seq_true.to(device)\n",
        "      seq_pred = model(seq_true)\n",
        "\n",
        "      loss = criterion(seq_pred, seq_true)\n",
        "\n",
        "      predictions.append(seq_pred.cpu().numpy().flatten())\n",
        "      losses.append(loss.item())\n",
        "  return predictions, losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0BWEkHKMmI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_, losses = predict(model, train_dataset)\n",
        "\n",
        "sns.distplot(losses, bins=50, kde=True);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObQto9huNtcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions, pred_losses = predict(model, test_normal_dataset)\n",
        "sns.distplot(pred_losses, bins=50, kde=True);\n",
        "correct = sum(l <= THRESHOLD for l in pred_losses)\n",
        "print(f'Correct normal predictions: {correct}/{len(test_normal_dataset)}')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}